import pandas as pd
import numpy as np
from math import log2
def entropy(target_col):
    elements, counts = np.unique(target_col, return_counts=True)
    return -np.sum([(counts[i]/np.sum(counts)) * log2(counts[i]/np.sum(counts)) for i in range(len(elements))])
def info_gain(data, feature, target="PlayTennis"):
    total_entropy = entropy(data[target])
    vals, counts = np.unique(data[feature], return_counts=True)
    weighted_entropy = np.sum([
        (counts[i]/np.sum(counts)) * entropy(data.where(data[feature] == vals[i]).dropna()[target])
        for i in range(len(vals))
    ])
    return total_entropy - weighted_entropy
def ID3(data, original_data, features, target="PlayTennis", parent_class=None):
    if len(np.unique(data[target])) == 1:
        return np.unique(data[target])[0]
    elif len(data) == 0:
        return np.unique(original_data[target])[
            np.argmax(np.unique(original_data[target], return_counts=True)[1])
        ]
    elif len(features) == 0:
        return parent_class
    else:
        parent_class = np.unique(data[target])[np.argmax(np.unique(data[target], return_counts=True)[1])]
        gains = [info_gain(data, feature, target) for feature in features]
        best_feature = features[np.argmax(gains)]
        tree = {best_feature: {}}
        features = [f for f in features if f != best_feature]
        for value in np.unique(data[best_feature]):
            subset = data.where(data[best_feature] == value).dropna()
            subtree = ID3(subset, data, features, target, parent_class)
            tree[best_feature][value] = subtree
        return tree
def predict(query, tree, default=None):
    for key in list(query.keys()):
        if key in tree:
            try:
                result = tree[key][query[key]]
            except:
                return default
            
            if isinstance(result, dict):
                return predict(query, result)
            else:
                return result
df = pd.read_csv("play_tennis.csv")
features = list(df.columns)
features.remove("PlayTennis")
tree = ID3(df, df, features)
print("Decision Tree:\n", tree)
new_sample = {'Outlook': 'Sunny', 'Temperature': 'Cool', 'Humidity': 'High', 'Wind': 'Strong'}
print("\nPrediction for new sample:", new_sample)
print("Predicted class:", predict(new_sample, tree))
